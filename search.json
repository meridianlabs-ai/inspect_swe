[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inspect SWE",
    "section": "",
    "text": "The inspect_swe package makes software engineering agents like Claude Code available as standard Inspect Agents. For example, here we use the claude_code() agent as the solver in an Inspect task:\nfrom inspect_ai import Task, task\nfrom inspect_ai.dataset import json_dataset\nfrom inspect_ai.scorer import model_graded_qa\n\nfrom inspect_swe import claude_code\n\n@task\ndef system_explorer() -&gt; Task:\n    return Task(\n        dataset=json_dataset(\"dataset.json\"),\n        solver=claude_code(),\n        scorer=model_graded_qa(),\n        sandbox=(\"docker\", \"Dockerfile\"),\n    )\nInspect SWE agents are implemented using the Inspect sandbox_agent_bridge(). Agents run inside the sample sandbox and their model API calls are proxied back to Inspect. This means that you can use any model with Inspect SWE agents and that features like token and time limits and log transcripts work as normal with the agents."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Inspect SWE",
    "section": "",
    "text": "The inspect_swe package makes software engineering agents like Claude Code available as standard Inspect Agents. For example, here we use the claude_code() agent as the solver in an Inspect task:\nfrom inspect_ai import Task, task\nfrom inspect_ai.dataset import json_dataset\nfrom inspect_ai.scorer import model_graded_qa\n\nfrom inspect_swe import claude_code\n\n@task\ndef system_explorer() -&gt; Task:\n    return Task(\n        dataset=json_dataset(\"dataset.json\"),\n        solver=claude_code(),\n        scorer=model_graded_qa(),\n        sandbox=(\"docker\", \"Dockerfile\"),\n    )\nInspect SWE agents are implemented using the Inspect sandbox_agent_bridge(). Agents run inside the sample sandbox and their model API calls are proxied back to Inspect. This means that you can use any model with Inspect SWE agents and that features like token and time limits and log transcripts work as normal with the agents."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Inspect SWE",
    "section": "Getting Started",
    "text": "Getting Started\nInspect SWE is currently under active development and also requires the development version of Inspect AI. To get started, install both development versions from GitHub:\npip install git+https://github.com/UKGovernmentBEIS/inspect_ai\npip install git+https://github.com/meridianlabs-ai/inspect_swe\nRead on below to learn about using the available agents (currently only Claude Code, but soon to include OpenAI Codex, Cline, and perhaps others)."
  },
  {
    "objectID": "index.html#claude-code",
    "href": "index.html#claude-code",
    "title": "Inspect SWE",
    "section": "Claude Code",
    "text": "Claude Code\nWhile Claude Code is typically used in an interactive loop by developers, it can also run in an unattended mode where it works on a solution to the prompt without interactions. The claude_code() agent runs in this mode within the sandbox, and its model API calls are proxied back to Inspect for handling by the model provider for the current task.\n\n\n\n\n\n\nClaude Code Installation\n\n\n\nBy default, the agent will download the current stable version of Claude Code and copy it to the sandbox. You can also exercise more explicit control over which version of Claude Code is used—see the Installation section below for details.\n\n\n\nUsing the Agent\nUse the claude_code() agent as you would any Inspect agent. For example, here we use it as the solver in an Inspect task:\nfrom inspect_ai import Task, task\nfrom inspect_ai.dataset import json_dataset\nfrom inspect_ai.scorer import model_graded_qa\n\nfrom inspect_swe import claude_code\n\n@task\ndef system_explorer() -&gt; Task:\n    return Task(\n        dataset=json_dataset(\"dataset.json\"),\n        solver=claude_code(),\n        scorer=model_graded_qa(),\n        sandbox=\"docker\",\n    )\nIf you want to try this out locally, see the system_explorer example.\n\n\nLog Viewer\nOne important productivity tip for working with the Claude Code agent is that the Messages view in the Log Viewer will provide the most coherent view of the agent’s path to the solution:\n\nWhile the Transcript view includes all of the same information, it also includes many additional model requests for supporting tasks (e.g. extracting the file paths from bash commands) which tend to distract from understanding the agent’s actions at a high level. Start with the Messages view, then use the transcript view as required for debugging.\n\n\nInstallation\nBy default, the agent will download the current stable version of Claude Code and copy it to the sandbox. You can override this behaviour using the version option:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n\"auto\"\nUse any available version of Claude Code in the sandbox, otherwise download the current stable version.\n\n\n\"sandbox\"\nUse the version of Claude Code in the sandbox (raises RuntimeError if not available in the sandbox)\n\n\n\"stable\"\nDownload and use the current stable version.\n\n\n\"latest\"\nDownload and use the very latest version.\n\n\n\"x.x.x\"\nDownload and use a specific version number.\n\n\n\nIf you don’t ever want to rely on automatic downloads of Claude Code (e.g. if you run your evaluations offline), you can use one of two approaches:\n\nPre-install the version of Claude Code you want to use in the sandbox, then use version=\"sandbox\":\nclaude_code(version=\"sandbox\")\nDownload the version of Claude Code you want to use into the cache, then specify that version explicitly:\n# download the desired version during installation/configuration\ndownload_claude_code(version=\"1.0.98\", platform=\"linux-x64\")\n\n# reference that version in your task (no download will occur)\nclaude_code(version=\"1.0.98\")\nNote that the 5 most recently downloaded versions are retained in the cache."
  }
]